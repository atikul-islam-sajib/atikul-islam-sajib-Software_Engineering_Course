{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yU0OJ7xSYJac"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchsummary import summary\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the dataset\n",
        "df = pd.read_csv('/content/Iris.csv')\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Pjvz63MWYrRx",
        "outputId": "441629d0-b416-4585-d10f-334d705b929b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
              "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
              "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
              "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
              "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
              "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4fd1e816-aff4-441d-8ce3-18ca276b2d9a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fd1e816-aff4-441d-8ce3-18ca276b2d9a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4fd1e816-aff4-441d-8ce3-18ca276b2d9a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4fd1e816-aff4-441d-8ce3-18ca276b2d9a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5242651e-4db8-45d2-a03c-f02479616250\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5242651e-4db8-45d2-a03c-f02479616250')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5242651e-4db8-45d2-a03c-f02479616250 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the Id columns\n",
        "df.drop(['Id'], axis = 1, inplace = True)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "r3kNPKYCY0Po",
        "outputId": "d0c65664-0f4f-46a6-c7c0-6267fe42db65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
              "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
              "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
              "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
              "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
              "4            5.0           3.6            1.4           0.2  Iris-setosa"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d951d44c-0ae9-453a-a103-4f117e4f8454\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d951d44c-0ae9-453a-a103-4f117e4f8454')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d951d44c-0ae9-453a-a103-4f117e4f8454 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d951d44c-0ae9-453a-a103-4f117e4f8454');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-35c8b69e-81a1-4fa8-a76c-941748002120\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35c8b69e-81a1-4fa8-a76c-941748002120')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-35c8b69e-81a1-4fa8-a76c-941748002120 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the columns\n",
        "list(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSfZHfxmY8BR",
        "outputId": "61583e83-cfc8-4838-948c-840522c86e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Species']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding\n",
        "df.iloc[:, -1] = df.iloc[:, -1].map({attribute: index for index, attribute in enumerate(df.iloc[:, -1].value_counts().index)})\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "q_FzQ-2tbKAs",
        "outputId": "7c2d72e0-b40c-4a13-90d4-73cb06638cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-d19da973b78a>:2: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  df.iloc[:, -1] = df.iloc[:, -1].map({attribute: index for index, attribute in enumerate(df.iloc[:, -1].value_counts().index)})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
              "0            5.1           3.5            1.4           0.2        0\n",
              "1            4.9           3.0            1.4           0.2        0\n",
              "2            4.7           3.2            1.3           0.2        0\n",
              "3            4.6           3.1            1.5           0.2        0\n",
              "4            5.0           3.6            1.4           0.2        0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ad07c3a-c388-41b5-999f-888f892e4950\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ad07c3a-c388-41b5-999f-888f892e4950')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8ad07c3a-c388-41b5-999f-888f892e4950 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8ad07c3a-c388-41b5-999f-888f892e4950');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0f27fd07-837c-4edc-b5e0-d3c7cc087fea\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0f27fd07-837c-4edc-b5e0-d3c7cc087fea')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0f27fd07-837c-4edc-b5e0-d3c7cc087fea button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns = df.columns\n",
        "\n",
        "# Preprocessing\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "standard_scaler  = StandardScaler()\n",
        "transformed_data = standard_scaler.fit_transform(X)\n",
        "X = pd.DataFrame(transformed_data, columns = columns[:-1])\n",
        "y = pd.DataFrame(y, columns = [columns[-1]])\n",
        "\n",
        "df = pd.concat([X, y], axis = 1)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wYJkv541YrUV",
        "outputId": "784717fa-0e02-4e75-c950-25de0c415c7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
              "0      -0.900681      1.032057      -1.341272     -1.312977        0\n",
              "1      -1.143017     -0.124958      -1.341272     -1.312977        0\n",
              "2      -1.385353      0.337848      -1.398138     -1.312977        0\n",
              "3      -1.506521      0.106445      -1.284407     -1.312977        0\n",
              "4      -1.021849      1.263460      -1.341272     -1.312977        0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d2d7d16-3808-4954-88f2-813ee5f3a4d4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.900681</td>\n",
              "      <td>1.032057</td>\n",
              "      <td>-1.341272</td>\n",
              "      <td>-1.312977</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.143017</td>\n",
              "      <td>-0.124958</td>\n",
              "      <td>-1.341272</td>\n",
              "      <td>-1.312977</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.385353</td>\n",
              "      <td>0.337848</td>\n",
              "      <td>-1.398138</td>\n",
              "      <td>-1.312977</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.506521</td>\n",
              "      <td>0.106445</td>\n",
              "      <td>-1.284407</td>\n",
              "      <td>-1.312977</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.021849</td>\n",
              "      <td>1.263460</td>\n",
              "      <td>-1.341272</td>\n",
              "      <td>-1.312977</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d2d7d16-3808-4954-88f2-813ee5f3a4d4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9d2d7d16-3808-4954-88f2-813ee5f3a4d4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9d2d7d16-3808-4954-88f2-813ee5f3a4d4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-353752d7-1f6d-44a9-bfaa-c61184b5abbb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-353752d7-1f6d-44a9-bfaa-c61184b5abbb')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-353752d7-1f6d-44a9-bfaa-c61184b5abbb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "# Split the dataset train & test\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
        "\n",
        "X_train = torch.tensor(data = X_train, dtype = torch.float32)\n",
        "X_test  = torch.tensor(data = X_test, dtype = torch.float32)\n",
        "\n",
        "# y_train = torch.tensor(data = y_train, dtype = torch.float32)\n",
        "# y_test  = torch.tensor(data = y_test, dtype = torch.float32)\n",
        "\n",
        "print(\"X_train shape # {} \".format(X_train.shape),'\\n')\n",
        "print(\"y_train shape # {} \".format(y_train.shape),'\\n')\n",
        "print(\"X_test shape  # {} \".format(X_test.shape),'\\n')\n",
        "print(\"y_test shape  # {} \".format(y_test.shape),'\\n')\n",
        "print(\"_\"*50)\n",
        "\n",
        "train_loader = DataLoader(dataset = list(zip(X_train, y_train)),\n",
        "                          batch_size = BATCH_SIZE,\n",
        "                          shuffle = True)\n",
        "\n",
        "test_loader  = DataLoader(dataset = list(zip(X_test, y_test)),\n",
        "                          batch_size = BATCH_SIZE,\n",
        "                          shuffle = True)\n",
        "\n",
        "train_data, train_label = next(iter(train_loader))\n",
        "print(\"\\nBatch size # {} \".format(train_loader.batch_size),'\\n')\n",
        "print(\"Train data with batch_size # {} \".format(train_data.shape),'\\n')\n",
        "print(\"Test  data with batch_size # {} \".format(train_label.shape),'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwPdMuzkdQcK",
        "outputId": "c437b247-467e-4c7c-8b72-d71f4bf3263b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape # torch.Size([120, 4])  \n",
            "\n",
            "y_train shape # (120,)  \n",
            "\n",
            "X_test shape  # torch.Size([30, 4])  \n",
            "\n",
            "y_test shape  # (30,)  \n",
            "\n",
            "__________________________________________________\n",
            "\n",
            "Batch size # 16  \n",
            "\n",
            "Train data with batch_size # torch.Size([16, 4])  \n",
            "\n",
            "Test  data with batch_size # torch.Size([16])  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "class ANN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.LEFT_LAYER  = self.left_fully_connected_layer(dropout  = 0.2)\n",
        "    self.RIGHT_LAYER = self.right_fully_connected_layer(dropout = 0.2)\n",
        "\n",
        "    self.OUT_LAYER   = self.output_layer()\n",
        "\n",
        "  def left_fully_connected_layer(self, dropout = None):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(in_features = 4, out_features = 16, bias = True),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Dropout(p = dropout),\n",
        "\n",
        "        nn.Linear(in_features = 16, out_features = 8, bias = True),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Dropout(p = dropout)\n",
        "\n",
        "    )\n",
        "\n",
        "  def right_fully_connected_layer(self, dropout = None):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(in_features = 4, out_features = 32, bias = True),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Dropout(p = dropout),\n",
        "\n",
        "        nn.Linear(in_features = 32, out_features = 16, bias = True),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Dropout(p = dropout)\n",
        "\n",
        "    )\n",
        "\n",
        "  def output_layer(self):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(in_features = 8 + 16, out_features = 16),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Dropout(p = 0.4),\n",
        "\n",
        "        nn.Linear(in_features = 16, out_features = 3),\n",
        "        nn.Softmax()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    LEFT  = self.LEFT_LAYER(x)\n",
        "    RIGHT = self.RIGHT_LAYER(x)\n",
        "\n",
        "    CONCAT = torch.concat((LEFT, RIGHT),dim = 1)\n",
        "\n",
        "    OUTPUT = self.OUT_LAYER(CONCAT)\n",
        "\n",
        "    return OUTPUT"
      ],
      "metadata": {
        "id": "lvDxXrsuYrWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ANN()"
      ],
      "metadata": {
        "id": "4VqpGKolYrYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59UA0WCuYrak",
        "outputId": "93f49345-aafa-4051-bd48-9658f9e24b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Module.parameters of ANN(\n",
            "  (LEFT_LAYER): Sequential(\n",
            "    (0): Linear(in_features=4, out_features=16, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.2, inplace=False)\n",
            "  )\n",
            "  (RIGHT_LAYER): Sequential(\n",
            "    (0): Linear(in_features=4, out_features=32, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.2, inplace=False)\n",
            "  )\n",
            "  (OUT_LAYER): Sequential(\n",
            "    (0): Linear(in_features=24, out_features=16, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.4, inplace=False)\n",
            "    (3): Linear(in_features=16, out_features=3, bias=True)\n",
            "    (4): Softmax(dim=None)\n",
            "  )\n",
            ")>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOTAL_PARAMS = 0\n",
        "for layer_name, params in model.named_parameters():\n",
        "  if params.requires_grad:\n",
        "    print(\"Layer # {} & trainable parameters # {} \".format(layer_name, params.numel()))\n",
        "    TOTAL_PARAMS = TOTAL_PARAMS + params.numel()\n",
        "\n",
        "print(\"\\n\", \"_\"*50,'\\n')\n",
        "print(\"Total trainable parameters # {} \".format(TOTAL_PARAMS).upper())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YVZFDl40ezc",
        "outputId": "13e3047e-e516-40f7-8f24-30cfd9e44cc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer # LEFT_LAYER.0.weight & trainable parameters # 64 \n",
            "Layer # LEFT_LAYER.0.bias & trainable parameters # 16 \n",
            "Layer # LEFT_LAYER.3.weight & trainable parameters # 128 \n",
            "Layer # LEFT_LAYER.3.bias & trainable parameters # 8 \n",
            "Layer # RIGHT_LAYER.0.weight & trainable parameters # 128 \n",
            "Layer # RIGHT_LAYER.0.bias & trainable parameters # 32 \n",
            "Layer # RIGHT_LAYER.3.weight & trainable parameters # 512 \n",
            "Layer # RIGHT_LAYER.3.bias & trainable parameters # 16 \n",
            "Layer # OUT_LAYER.0.weight & trainable parameters # 384 \n",
            "Layer # OUT_LAYER.0.bias & trainable parameters # 16 \n",
            "Layer # OUT_LAYER.3.weight & trainable parameters # 48 \n",
            "Layer # OUT_LAYER.3.bias & trainable parameters # 3 \n",
            "\n",
            " __________________________________________________ \n",
            "\n",
            "TOTAL TRAINABLE PARAMETERS # 1355 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape[1:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNAh_d4b2I8A",
        "outputId": "76beac38-3cb1-448b-e806-7417efa438d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model = model, input_size = X_train.shape[1:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAyi0oyh1r2Z",
        "outputId": "c74fcb29-5149-4710-cd3e-0607f5bd4bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                   [-1, 16]              80\n",
            "              ReLU-2                   [-1, 16]               0\n",
            "           Dropout-3                   [-1, 16]               0\n",
            "            Linear-4                    [-1, 8]             136\n",
            "              ReLU-5                    [-1, 8]               0\n",
            "           Dropout-6                    [-1, 8]               0\n",
            "            Linear-7                   [-1, 32]             160\n",
            "              ReLU-8                   [-1, 32]               0\n",
            "           Dropout-9                   [-1, 32]               0\n",
            "           Linear-10                   [-1, 16]             528\n",
            "             ReLU-11                   [-1, 16]               0\n",
            "          Dropout-12                   [-1, 16]               0\n",
            "           Linear-13                   [-1, 16]             400\n",
            "             ReLU-14                   [-1, 16]               0\n",
            "          Dropout-15                   [-1, 16]               0\n",
            "           Linear-16                    [-1, 3]              51\n",
            "          Softmax-17                    [-1, 3]               0\n",
            "================================================================\n",
            "Total params: 1,355\n",
            "Trainable params: 1,355\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.01\n",
            "Estimated Total Size (MB): 0.01\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(params = model.parameters(), lr = 0.001)\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "_n_o_MkEYrcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, epochs = 100, model = None, train_loader = None, val_loader = None):\n",
        "        if model is not None and train_loader is not None and val_loader is not None:\n",
        "            self.EPOCHS  = epochs\n",
        "            self.history = {'loss'    : [],\n",
        "                            'val_loss': [],\n",
        "                            'accuracy': [],\n",
        "                            'val_accuracy': []\n",
        "                            }\n",
        "            self.model = model\n",
        "            self.loss_function = nn.CrossEntropyLoss()\n",
        "            self.optimizer = optim.AdamW(params = self.model.parameters(), lr = 0.001)\n",
        "            self.train_loader = train_loader\n",
        "            self.val_loader = val_loader\n",
        "        else:\n",
        "            raise \"Model is not defined.\".title()\n",
        "\n",
        "    def _model_prediction(self, model, data):\n",
        "      return model(data)\n",
        "    def _compute_labels(self, predicted):\n",
        "      return torch.argmax(predicted, dim = 1)\n",
        "    def _compute_loss(self, predicted, actual):\n",
        "      return self.loss_function(predicted, actual)\n",
        "    def _do_backpropagation(self, optimizer, loss_function):\n",
        "      optimizer.zero_grad()\n",
        "      loss_function.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    def train(self):\n",
        "        TRAIN_LOSS     = []\n",
        "        VAL_ACCURACY   = []\n",
        "        for epoch in range(self.EPOCHS):\n",
        "          for (X_batch, y_batch) in self.train_loader:\n",
        "            train_prediction = self._model_prediction(model = self.model, data = X_batch)\n",
        "            train_loss_compute = self._compute_loss(predicted = train_prediction, actual = y_batch)\n",
        "            self._do_backpropagation(optimizer = self.optimizer, loss_function = train_loss_compute)\n",
        "\n",
        "          train_predicted  = self._compute_labels(train_prediction)\n",
        "          TRAIN_LOSS.append(train_loss_compute.item())\n",
        "          train_accuracy = accuracy_score(train_predicted, y_batch)\n",
        "          print(train_accuracy)\n",
        "          self.history['loss'].append(np.array(TRAIN_LOSS).mean())\n",
        "          self.history['accuracy'].append(train_accuracy)\n",
        "\n",
        "          VAL_LOSS = []\n",
        "\n",
        "          for (val_data, val_label) in self.val_loader:\n",
        "            test_prediction = self._model_prediction(model = self.model, data = val_data)\n",
        "            test_loss_compute = self._compute_loss(predicted = test_prediction, actual = val_label)\n",
        "\n",
        "\n",
        "          test_predicted  = self._compute_labels(test_prediction)\n",
        "          VAL_LOSS.append(test_loss_compute.item())\n",
        "          test_accuracy = accuracy_score(test_predicted, val_label)\n",
        "          print(test_accuracy)\n",
        "          self.history['val_loss'].append(np.array(VAL_LOSS).mean())\n",
        "          self.history['val_accuracy'].append(test_accuracy)\n",
        "\n",
        "          print(\"Epoch {}/{} \".format(epoch, self.EPOCHS))\n",
        "          print(\"[==========] loss - {} accuracy - {} - val_loss - {} val_accuracy - {} \".format(TRAIN_LOSS,\n",
        "                                                                                                 train_accuracy,\n",
        "                                                                                                 VAL_LOSS,\n",
        "                                                                                                 test_accuracy))\n"
      ],
      "metadata": {
        "id": "sk6w62Bt-XqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(epochs = 100, model = model, train_loader = train_loader, val_loader = test_loader)\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hQKCtCe-Xs1",
        "outputId": "752abf23-bd74-4122-8b95-3aca109cb345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.25\n",
            "0.5\n",
            "Epoch 0/100 \n",
            "[==========] loss - [1.098218321800232] accuracy - 0.25 - val_loss - [1.0932284593582153] val_accuracy - 0.5 \n",
            "0.625\n",
            "0.2857142857142857\n",
            "Epoch 1/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706] accuracy - 0.625 - val_loss - [1.0990239381790161] val_accuracy - 0.2857142857142857 \n",
            "0.5\n",
            "0.42857142857142855\n",
            "Epoch 2/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308] accuracy - 0.5 - val_loss - [1.0925203561782837] val_accuracy - 0.42857142857142855 \n",
            "0.5\n",
            "0.5714285714285714\n",
            "Epoch 3/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616] accuracy - 0.5 - val_loss - [1.0852863788604736] val_accuracy - 0.5714285714285714 \n",
            "0.5\n",
            "0.5\n",
            "Epoch 4/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553] accuracy - 0.5 - val_loss - [1.0761340856552124] val_accuracy - 0.5 \n",
            "0.75\n",
            "0.5714285714285714\n",
            "Epoch 5/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203] accuracy - 0.75 - val_loss - [1.0744692087173462] val_accuracy - 0.5714285714285714 \n",
            "0.75\n",
            "0.6428571428571429\n",
            "Epoch 6/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485] accuracy - 0.75 - val_loss - [1.0171632766723633] val_accuracy - 0.6428571428571429 \n",
            "0.5\n",
            "0.6428571428571429\n",
            "Epoch 7/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729] accuracy - 0.5 - val_loss - [1.032631516456604] val_accuracy - 0.6428571428571429 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.75\n",
            "0.6428571428571429\n",
            "Epoch 8/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663] accuracy - 0.75 - val_loss - [1.0161901712417603] val_accuracy - 0.6428571428571429 \n",
            "0.625\n",
            "0.6428571428571429\n",
            "Epoch 9/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838] accuracy - 0.625 - val_loss - [0.9381935000419617] val_accuracy - 0.6428571428571429 \n",
            "0.375\n",
            "0.7142857142857143\n",
            "Epoch 10/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038] accuracy - 0.375 - val_loss - [0.9386695027351379] val_accuracy - 0.7142857142857143 \n",
            "0.75\n",
            "0.5714285714285714\n",
            "Epoch 11/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577] accuracy - 0.75 - val_loss - [0.9677954912185669] val_accuracy - 0.5714285714285714 \n",
            "0.375\n",
            "0.6428571428571429\n",
            "Epoch 12/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875] accuracy - 0.375 - val_loss - [0.906758725643158] val_accuracy - 0.6428571428571429 \n",
            "0.5\n",
            "0.7142857142857143\n",
            "Epoch 13/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424] accuracy - 0.5 - val_loss - [0.7989991307258606] val_accuracy - 0.7142857142857143 \n",
            "0.375\n",
            "0.7857142857142857\n",
            "Epoch 14/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082] accuracy - 0.375 - val_loss - [0.7982643842697144] val_accuracy - 0.7857142857142857 \n",
            "0.625\n",
            "0.7142857142857143\n",
            "Epoch 15/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228] accuracy - 0.625 - val_loss - [0.8974015116691589] val_accuracy - 0.7142857142857143 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.75\n",
            "0.7857142857142857\n",
            "Epoch 16/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004] accuracy - 0.75 - val_loss - [0.81697016954422] val_accuracy - 0.7857142857142857 \n",
            "0.625\n",
            "0.7142857142857143\n",
            "Epoch 17/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305] accuracy - 0.625 - val_loss - [0.762942373752594] val_accuracy - 0.7142857142857143 \n",
            "0.625\n",
            "0.7857142857142857\n",
            "Epoch 18/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699] accuracy - 0.625 - val_loss - [0.7452960014343262] val_accuracy - 0.7857142857142857 \n",
            "0.625\n",
            "0.6428571428571429\n",
            "Epoch 19/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909] accuracy - 0.625 - val_loss - [0.8058391809463501] val_accuracy - 0.6428571428571429 \n",
            "0.625\n",
            "0.5\n",
            "Epoch 20/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832] accuracy - 0.625 - val_loss - [0.8938191533088684] val_accuracy - 0.5 \n",
            "0.625\n",
            "0.5714285714285714\n",
            "Epoch 21/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789] accuracy - 0.625 - val_loss - [0.8458779454231262] val_accuracy - 0.5714285714285714 \n",
            "0.625\n",
            "0.5714285714285714\n",
            "Epoch 22/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676] accuracy - 0.625 - val_loss - [0.824015200138092] val_accuracy - 0.5714285714285714 \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7142857142857143\n",
            "Epoch 23/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151] accuracy - 1.0 - val_loss - [0.7997725605964661] val_accuracy - 0.7142857142857143 \n",
            "0.875\n",
            "0.7142857142857143\n",
            "Epoch 24/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022] accuracy - 0.875 - val_loss - [0.7747645378112793] val_accuracy - 0.7142857142857143 \n",
            "0.625\n",
            "0.7857142857142857\n",
            "Epoch 25/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337] accuracy - 0.625 - val_loss - [0.8215379118919373] val_accuracy - 0.7857142857142857 \n",
            "0.75\n",
            "0.8571428571428571\n",
            "Epoch 26/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914] accuracy - 0.75 - val_loss - [0.752133846282959] val_accuracy - 0.8571428571428571 \n",
            "0.625\n",
            "0.8571428571428571\n",
            "Epoch 27/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762] accuracy - 0.625 - val_loss - [0.6930572390556335] val_accuracy - 0.8571428571428571 \n",
            "0.5\n",
            "0.6428571428571429\n",
            "Epoch 28/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916] accuracy - 0.5 - val_loss - [0.8011249899864197] val_accuracy - 0.6428571428571429 \n",
            "0.625\n",
            "0.6428571428571429\n",
            "Epoch 29/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272] accuracy - 0.625 - val_loss - [0.8785277605056763] val_accuracy - 0.6428571428571429 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n",
            "0.5\n",
            "Epoch 30/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461] accuracy - 0.5 - val_loss - [0.8401302695274353] val_accuracy - 0.5 \n",
            "0.625\n",
            "0.7142857142857143\n",
            "Epoch 31/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175] accuracy - 0.625 - val_loss - [0.7380347847938538] val_accuracy - 0.7142857142857143 \n",
            "0.875\n",
            "0.8571428571428571\n",
            "Epoch 32/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029] accuracy - 0.875 - val_loss - [0.7042065262794495] val_accuracy - 0.8571428571428571 \n",
            "0.5\n",
            "0.8571428571428571\n",
            "Epoch 33/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812] accuracy - 0.5 - val_loss - [0.7506434321403503] val_accuracy - 0.8571428571428571 \n",
            "0.875\n",
            "0.7142857142857143\n",
            "Epoch 34/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643] accuracy - 0.875 - val_loss - [0.7411079406738281] val_accuracy - 0.7142857142857143 \n",
            "0.875\n",
            "0.7142857142857143\n",
            "Epoch 35/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866] accuracy - 0.875 - val_loss - [0.7405598759651184] val_accuracy - 0.7142857142857143 \n",
            "1.0\n",
            "0.8571428571428571\n",
            "Epoch 36/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628] accuracy - 1.0 - val_loss - [0.7252780795097351] val_accuracy - 0.8571428571428571 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.875\n",
            "0.7142857142857143\n",
            "Epoch 37/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476] accuracy - 0.875 - val_loss - [0.7529379725456238] val_accuracy - 0.7142857142857143 \n",
            "0.375\n",
            "0.9285714285714286\n",
            "Epoch 38/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585] accuracy - 0.375 - val_loss - [0.6545929908752441] val_accuracy - 0.9285714285714286 \n",
            "0.875\n",
            "0.7857142857142857\n",
            "Epoch 39/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176] accuracy - 0.875 - val_loss - [0.7648072242736816] val_accuracy - 0.7857142857142857 \n",
            "0.875\n",
            "0.8571428571428571\n",
            "Epoch 40/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368] accuracy - 0.875 - val_loss - [0.7643364071846008] val_accuracy - 0.8571428571428571 \n",
            "0.75\n",
            "0.7857142857142857\n",
            "Epoch 41/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674] accuracy - 0.75 - val_loss - [0.7719751000404358] val_accuracy - 0.7857142857142857 \n",
            "1.0\n",
            "0.7142857142857143\n",
            "Epoch 42/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759] accuracy - 1.0 - val_loss - [0.7523635029792786] val_accuracy - 0.7142857142857143 \n",
            "1.0\n",
            "0.7857142857142857\n",
            "Epoch 43/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384] accuracy - 1.0 - val_loss - [0.7293981909751892] val_accuracy - 0.7857142857142857 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.875\n",
            "0.7857142857142857\n",
            "Epoch 44/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917] accuracy - 0.875 - val_loss - [0.7459498643875122] val_accuracy - 0.7857142857142857 \n",
            "0.75\n",
            "0.9285714285714286\n",
            "Epoch 45/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446] accuracy - 0.75 - val_loss - [0.6621112823486328] val_accuracy - 0.9285714285714286 \n",
            "1.0\n",
            "1.0\n",
            "Epoch 46/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732] accuracy - 1.0 - val_loss - [0.6548784971237183] val_accuracy - 1.0 \n",
            "0.875\n",
            "0.9285714285714286\n",
            "Epoch 47/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989] accuracy - 0.875 - val_loss - [0.679934561252594] val_accuracy - 0.9285714285714286 \n",
            "1.0\n",
            "0.9285714285714286\n",
            "Epoch 48/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098] accuracy - 1.0 - val_loss - [0.6960216760635376] val_accuracy - 0.9285714285714286 \n",
            "0.875\n",
            "0.9285714285714286\n",
            "Epoch 49/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846] accuracy - 0.875 - val_loss - [0.6952048540115356] val_accuracy - 0.9285714285714286 \n",
            "0.75\n",
            "0.9285714285714286\n",
            "Epoch 50/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799] accuracy - 0.75 - val_loss - [0.7063202261924744] val_accuracy - 0.9285714285714286 \n",
            "0.875\n",
            "0.7857142857142857\n",
            "Epoch 51/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162] accuracy - 0.875 - val_loss - [0.7419065237045288] val_accuracy - 0.7857142857142857 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.875\n",
            "0.9285714285714286\n",
            "Epoch 52/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701] accuracy - 0.875 - val_loss - [0.6992124915122986] val_accuracy - 0.9285714285714286 \n",
            "0.875\n",
            "0.8571428571428571\n",
            "Epoch 53/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694] accuracy - 0.875 - val_loss - [0.7097547650337219] val_accuracy - 0.8571428571428571 \n",
            "0.875\n",
            "0.8571428571428571\n",
            "Epoch 54/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343] accuracy - 0.875 - val_loss - [0.6757597923278809] val_accuracy - 0.8571428571428571 \n",
            "1.0\n",
            "0.8571428571428571\n",
            "Epoch 55/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839] accuracy - 1.0 - val_loss - [0.749363124370575] val_accuracy - 0.8571428571428571 \n",
            "0.875\n",
            "1.0\n",
            "Epoch 56/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052] accuracy - 0.875 - val_loss - [0.6294301152229309] val_accuracy - 1.0 \n",
            "0.875\n",
            "0.9285714285714286\n",
            "Epoch 57/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851] accuracy - 0.875 - val_loss - [0.7198384404182434] val_accuracy - 0.9285714285714286 \n",
            "0.75\n",
            "1.0\n",
            "Epoch 58/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193] accuracy - 0.75 - val_loss - [0.6207658648490906] val_accuracy - 1.0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.875\n",
            "1.0\n",
            "Epoch 59/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154] accuracy - 0.875 - val_loss - [0.5809926986694336] val_accuracy - 1.0 \n",
            "1.0\n",
            "0.9285714285714286\n",
            "Epoch 60/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232] accuracy - 1.0 - val_loss - [0.6398184895515442] val_accuracy - 0.9285714285714286 \n",
            "0.75\n",
            "0.9285714285714286\n",
            "Epoch 61/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956] accuracy - 0.75 - val_loss - [0.6816111207008362] val_accuracy - 0.9285714285714286 \n",
            "0.75\n",
            "1.0\n",
            "Epoch 62/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153] accuracy - 0.75 - val_loss - [0.6270170211791992] val_accuracy - 1.0 \n",
            "1.0\n",
            "1.0\n",
            "Epoch 63/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673] accuracy - 1.0 - val_loss - [0.6142902374267578] val_accuracy - 1.0 \n",
            "0.875\n",
            "0.8571428571428571\n",
            "Epoch 64/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524] accuracy - 0.875 - val_loss - [0.6676744222640991] val_accuracy - 0.8571428571428571 \n",
            "0.875\n",
            "0.8571428571428571\n",
            "Epoch 65/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359] accuracy - 0.875 - val_loss - [0.7208504676818848] val_accuracy - 0.8571428571428571 \n",
            "0.875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "Epoch 66/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343] accuracy - 0.875 - val_loss - [0.6237868070602417] val_accuracy - 1.0 \n",
            "1.0\n",
            "1.0\n",
            "Epoch 67/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553] accuracy - 1.0 - val_loss - [0.6207208037376404] val_accuracy - 1.0 \n",
            "1.0\n",
            "0.8571428571428571\n",
            "Epoch 68/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303] accuracy - 1.0 - val_loss - [0.6845678687095642] val_accuracy - 0.8571428571428571 \n",
            "1.0\n",
            "0.8571428571428571\n",
            "Epoch 69/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908] accuracy - 1.0 - val_loss - [0.6871480345726013] val_accuracy - 0.8571428571428571 \n",
            "0.875\n",
            "0.9285714285714286\n",
            "Epoch 70/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455] accuracy - 0.875 - val_loss - [0.7129063606262207] val_accuracy - 0.9285714285714286 \n",
            "0.875\n",
            "0.7857142857142857\n",
            "Epoch 71/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211] accuracy - 0.875 - val_loss - [0.7694582343101501] val_accuracy - 0.7857142857142857 \n",
            "1.0\n",
            "1.0\n",
            "Epoch 72/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317] accuracy - 1.0 - val_loss - [0.6054546236991882] val_accuracy - 1.0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.875\n",
            "0.9285714285714286\n",
            "Epoch 73/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169] accuracy - 0.875 - val_loss - [0.6758547425270081] val_accuracy - 0.9285714285714286 \n",
            "0.75\n",
            "0.9285714285714286\n",
            "Epoch 74/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417] accuracy - 0.75 - val_loss - [0.69039386510849] val_accuracy - 0.9285714285714286 \n",
            "0.875\n",
            "1.0\n",
            "Epoch 75/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351] accuracy - 0.875 - val_loss - [0.6115205883979797] val_accuracy - 1.0 \n",
            "1.0\n",
            "1.0\n",
            "Epoch 76/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334] accuracy - 1.0 - val_loss - [0.6084652543067932] val_accuracy - 1.0 \n",
            "0.75\n",
            "1.0\n",
            "Epoch 77/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801] accuracy - 0.75 - val_loss - [0.614362895488739] val_accuracy - 1.0 \n",
            "1.0\n",
            "0.7857142857142857\n",
            "Epoch 78/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801, 0.5620013475418091] accuracy - 1.0 - val_loss - [0.7389049530029297] val_accuracy - 0.7857142857142857 \n",
            "1.0\n",
            "1.0\n",
            "Epoch 79/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801, 0.5620013475418091, 0.6675448417663574] accuracy - 1.0 - val_loss - [0.6169352531433105] val_accuracy - 1.0 \n",
            "0.875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "Epoch 80/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801, 0.5620013475418091, 0.6675448417663574, 0.7332165837287903] accuracy - 0.875 - val_loss - [0.5702831745147705] val_accuracy - 1.0 \n",
            "1.0\n",
            "0.8571428571428571\n",
            "Epoch 81/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801, 0.5620013475418091, 0.6675448417663574, 0.7332165837287903, 0.6653296947479248] accuracy - 1.0 - val_loss - [0.6497811079025269] val_accuracy - 0.8571428571428571 \n",
            "1.0\n",
            "1.0\n",
            "Epoch 82/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801, 0.5620013475418091, 0.6675448417663574, 0.7332165837287903, 0.6653296947479248, 0.5780139565467834] accuracy - 1.0 - val_loss - [0.6200329661369324] val_accuracy - 1.0 \n",
            "0.875\n",
            "1.0\n",
            "Epoch 83/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801, 0.5620013475418091, 0.6675448417663574, 0.7332165837287903, 0.6653296947479248, 0.5780139565467834, 0.6458042860031128] accuracy - 0.875 - val_loss - [0.6340669989585876] val_accuracy - 1.0 \n",
            "0.75\n",
            "1.0\n",
            "Epoch 84/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801, 0.5620013475418091, 0.6675448417663574, 0.7332165837287903, 0.6653296947479248, 0.5780139565467834, 0.6458042860031128, 0.7788954377174377] accuracy - 0.75 - val_loss - [0.5818095803260803] val_accuracy - 1.0 \n",
            "0.75\n",
            "1.0\n",
            "Epoch 85/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801, 0.5620013475418091, 0.6675448417663574, 0.7332165837287903, 0.6653296947479248, 0.5780139565467834, 0.6458042860031128, 0.7788954377174377, 0.7596923112869263] accuracy - 0.75 - val_loss - [0.6122360229492188] val_accuracy - 1.0 \n",
            "1.0\n",
            "0.9285714285714286\n",
            "Epoch 86/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801, 0.5620013475418091, 0.6675448417663574, 0.7332165837287903, 0.6653296947479248, 0.5780139565467834, 0.6458042860031128, 0.7788954377174377, 0.7596923112869263, 0.5878685712814331] accuracy - 1.0 - val_loss - [0.6391814947128296] val_accuracy - 0.9285714285714286 \n",
            "1.0"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1.0\n",
            "Epoch 87/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801, 0.5620013475418091, 0.6675448417663574, 0.7332165837287903, 0.6653296947479248, 0.5780139565467834, 0.6458042860031128, 0.7788954377174377, 0.7596923112869263, 0.5878685712814331, 0.5773393511772156] accuracy - 1.0 - val_loss - [0.5989142656326294] val_accuracy - 1.0 \n",
            "0.75\n",
            "0.8571428571428571\n",
            "Epoch 88/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801, 0.5620013475418091, 0.6675448417663574, 0.7332165837287903, 0.6653296947479248, 0.5780139565467834, 0.6458042860031128, 0.7788954377174377, 0.7596923112869263, 0.5878685712814331, 0.5773393511772156, 0.7355030179023743] accuracy - 0.75 - val_loss - [0.6785858273506165] val_accuracy - 0.8571428571428571 \n",
            "1.0\n",
            "1.0\n",
            "Epoch 89/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801, 0.5620013475418091, 0.6675448417663574, 0.7332165837287903, 0.6653296947479248, 0.5780139565467834, 0.6458042860031128, 0.7788954377174377, 0.7596923112869263, 0.5878685712814331, 0.5773393511772156, 0.7355030179023743, 0.5838404893875122] accuracy - 1.0 - val_loss - [0.6496875882148743] val_accuracy - 1.0 \n",
            "1.0\n",
            "1.0\n",
            "Epoch 90/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801, 0.5620013475418091, 0.6675448417663574, 0.7332165837287903, 0.6653296947479248, 0.5780139565467834, 0.6458042860031128, 0.7788954377174377, 0.7596923112869263, 0.5878685712814331, 0.5773393511772156, 0.7355030179023743, 0.5838404893875122, 0.6490606665611267] accuracy - 1.0 - val_loss - [0.6142165064811707] val_accuracy - 1.0 \n",
            "1.0\n",
            "1.0\n",
            "Epoch 91/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801, 0.5620013475418091, 0.6675448417663574, 0.7332165837287903, 0.6653296947479248, 0.5780139565467834, 0.6458042860031128, 0.7788954377174377, 0.7596923112869263, 0.5878685712814331, 0.5773393511772156, 0.7355030179023743, 0.5838404893875122, 0.6490606665611267, 0.5929368734359741] accuracy - 1.0 - val_loss - [0.5787217020988464] val_accuracy - 1.0 \n",
            "0.875\n",
            "1.0\n",
            "Epoch 92/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801, 0.5620013475418091, 0.6675448417663574, 0.7332165837287903, 0.6653296947479248, 0.5780139565467834, 0.6458042860031128, 0.7788954377174377, 0.7596923112869263, 0.5878685712814331, 0.5773393511772156, 0.7355030179023743, 0.5838404893875122, 0.6490606665611267, 0.5929368734359741, 0.6728166937828064] accuracy - 0.875 - val_loss - [0.5849419236183167] val_accuracy - 1.0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.875\n",
            "1.0\n",
            "Epoch 93/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801, 0.5620013475418091, 0.6675448417663574, 0.7332165837287903, 0.6653296947479248, 0.5780139565467834, 0.6458042860031128, 0.7788954377174377, 0.7596923112869263, 0.5878685712814331, 0.5773393511772156, 0.7355030179023743, 0.5838404893875122, 0.6490606665611267, 0.5929368734359741, 0.6728166937828064, 0.6433420181274414] accuracy - 0.875 - val_loss - [0.5606938004493713] val_accuracy - 1.0 \n",
            "1.0\n",
            "0.8571428571428571\n",
            "Epoch 94/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801, 0.5620013475418091, 0.6675448417663574, 0.7332165837287903, 0.6653296947479248, 0.5780139565467834, 0.6458042860031128, 0.7788954377174377, 0.7596923112869263, 0.5878685712814331, 0.5773393511772156, 0.7355030179023743, 0.5838404893875122, 0.6490606665611267, 0.5929368734359741, 0.6728166937828064, 0.6433420181274414, 0.5918669104576111] accuracy - 1.0 - val_loss - [0.6728977560997009] val_accuracy - 0.8571428571428571 \n",
            "0.875\n",
            "0.9285714285714286\n",
            "Epoch 95/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801, 0.5620013475418091, 0.6675448417663574, 0.7332165837287903, 0.6653296947479248, 0.5780139565467834, 0.6458042860031128, 0.7788954377174377, 0.7596923112869263, 0.5878685712814331, 0.5773393511772156, 0.7355030179023743, 0.5838404893875122, 0.6490606665611267, 0.5929368734359741, 0.6728166937828064, 0.6433420181274414, 0.5918669104576111, 0.6058081388473511] accuracy - 0.875 - val_loss - [0.6585920453071594] val_accuracy - 0.9285714285714286 \n",
            "1.0\n",
            "1.0\n",
            "Epoch 96/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801, 0.5620013475418091, 0.6675448417663574, 0.7332165837287903, 0.6653296947479248, 0.5780139565467834, 0.6458042860031128, 0.7788954377174377, 0.7596923112869263, 0.5878685712814331, 0.5773393511772156, 0.7355030179023743, 0.5838404893875122, 0.6490606665611267, 0.5929368734359741, 0.6728166937828064, 0.6433420181274414, 0.5918669104576111, 0.6058081388473511, 0.6044417023658752] accuracy - 1.0 - val_loss - [0.5879257917404175] val_accuracy - 1.0 \n",
            "1.0\n",
            "0.9285714285714286\n",
            "Epoch 97/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801, 0.5620013475418091, 0.6675448417663574, 0.7332165837287903, 0.6653296947479248, 0.5780139565467834, 0.6458042860031128, 0.7788954377174377, 0.7596923112869263, 0.5878685712814331, 0.5773393511772156, 0.7355030179023743, 0.5838404893875122, 0.6490606665611267, 0.5929368734359741, 0.6728166937828064, 0.6433420181274414, 0.5918669104576111, 0.6058081388473511, 0.6044417023658752, 0.5982593894004822] accuracy - 1.0 - val_loss - [0.6242536902427673] val_accuracy - 0.9285714285714286 \n",
            "0.875\n",
            "1.0\n",
            "Epoch 98/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801, 0.5620013475418091, 0.6675448417663574, 0.7332165837287903, 0.6653296947479248, 0.5780139565467834, 0.6458042860031128, 0.7788954377174377, 0.7596923112869263, 0.5878685712814331, 0.5773393511772156, 0.7355030179023743, 0.5838404893875122, 0.6490606665611267, 0.5929368734359741, 0.6728166937828064, 0.6433420181274414, 0.5918669104576111, 0.6058081388473511, 0.6044417023658752, 0.5982593894004822, 0.6375651955604553] accuracy - 0.875 - val_loss - [0.6067805886268616] val_accuracy - 1.0 \n",
            "0.875\n",
            "1.0\n",
            "Epoch 99/100 \n",
            "[==========] loss - [1.098218321800232, 1.088738203048706, 1.092965006828308, 1.0518449544906616, 1.0753133296966553, 1.0199451446533203, 1.0281349420547485, 1.0313951969146729, 0.9245124459266663, 0.8798658847808838, 1.0238584280014038, 0.8883500695228577, 0.958465576171875, 0.9433109760284424, 0.9865157008171082, 0.8359035849571228, 0.8417649269104004, 0.7810733914375305, 0.8764874339103699, 0.8321676850318909, 0.8856551051139832, 0.9007730484008789, 0.859016478061676, 0.7072620987892151, 0.7152704000473022, 0.8516106009483337, 0.7443591952323914, 0.7880816459655762, 0.9070589542388916, 0.9153781533241272, 0.8722026944160461, 0.8000839948654175, 0.6723718047142029, 0.8970493078231812, 0.7746517658233643, 0.7049556374549866, 0.5855625867843628, 0.7721112966537476, 1.0080331563949585, 0.735603392124176, 0.7378336191177368, 0.8691227436065674, 0.675957977771759, 0.6880192160606384, 0.7160109281539917, 0.8474241495132446, 0.7077588438987732, 0.6535302400588989, 0.7788643836975098, 0.6987717151641846, 0.7841160297393799, 0.6764125227928162, 0.7133855223655701, 0.6607030630111694, 0.776633083820343, 0.6622025370597839, 0.766498863697052, 0.6542981863021851, 0.7497613430023193, 0.8467645049095154, 0.6133334636688232, 0.8627861738204956, 0.7443554997444153, 0.6359764337539673, 0.7732988595962524, 0.7399806976318359, 0.7238771319389343, 0.5795857906341553, 0.6087300777435303, 0.7556375861167908, 0.7273611426353455, 0.7397298812866211, 0.6768515706062317, 0.7735165953636169, 0.7458531260490417, 0.6898776888847351, 0.6349597573280334, 0.7206194996833801, 0.5620013475418091, 0.6675448417663574, 0.7332165837287903, 0.6653296947479248, 0.5780139565467834, 0.6458042860031128, 0.7788954377174377, 0.7596923112869263, 0.5878685712814331, 0.5773393511772156, 0.7355030179023743, 0.5838404893875122, 0.6490606665611267, 0.5929368734359741, 0.6728166937828064, 0.6433420181274414, 0.5918669104576111, 0.6058081388473511, 0.6044417023658752, 0.5982593894004822, 0.6375651955604553, 0.7301478981971741] accuracy - 0.875 - val_loss - [0.5668149590492249] val_accuracy - 1.0 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.history['accuracy']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEUDsMuA-Xvn",
        "outputId": "9f6f4c23-9082-403d-f203-c7183c43c3e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.25,\n",
              " 0.625,\n",
              " 0.5,\n",
              " 0.5,\n",
              " 0.5,\n",
              " 0.75,\n",
              " 0.75,\n",
              " 0.5,\n",
              " 0.75,\n",
              " 0.625,\n",
              " 0.375,\n",
              " 0.75,\n",
              " 0.375,\n",
              " 0.5,\n",
              " 0.375,\n",
              " 0.625,\n",
              " 0.75,\n",
              " 0.625,\n",
              " 0.625,\n",
              " 0.625,\n",
              " 0.625,\n",
              " 0.625,\n",
              " 0.625,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.625,\n",
              " 0.75,\n",
              " 0.625,\n",
              " 0.5,\n",
              " 0.625,\n",
              " 0.5,\n",
              " 0.625,\n",
              " 0.875,\n",
              " 0.5,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.375,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 0.75,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.75,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.75,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 0.75,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 0.75,\n",
              " 0.75,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.75,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 0.75,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.75,\n",
              " 0.75,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.75,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.875]"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, axes = plt.subplots(1, 2)\n",
        "\n",
        "axes[0].plot(trainer.history['loss'], label = 'train_loss')\n",
        "axes[0].plot(trainer.history['val_loss'], label = 'val_loss')\n",
        "axes[0].set_title('train and test loss')\n",
        "\n",
        "axes[1].plot(trainer.history['accuracy'], label = 'train_accuracy')\n",
        "axes[1].plot(trainer.history['val_accuracy'], label = 'val_accuracy')\n",
        "axes[1].set_title('train and test accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "cEuxnSklas7I",
        "outputId": "eba0ba0d-5391-4cda-e195-68a772bf9236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "WQjXuPaEwHzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# anonymous functions based on functional programming\n",
        "def compute_correct_prediction(predict = None, actual = None):\n",
        "  if isinstance(predict, list) and isinstance(actual, list):\n",
        "    correct_predict = sum(map(lambda x, y: x == y, predict, actual))\n",
        "    return correct_predict\n",
        "  else:\n",
        "    raise \"pass the predict & actual value in correct format\".title()\n",
        "\n",
        "# Only final data structures\n",
        "def evaluate_accuracy(predict = None, actual = None):\n",
        "  return accuracy_score(actual, predict)\n",
        "\n",
        "def evaluate_precision(predict = None, actual = None):\n",
        "  return precision_score(actual, predict, average = 'macro')\n",
        "\n",
        "def evaluate_recall(predict = None, actual = None):\n",
        "  return recall_score(actual, predict, average = 'macro')\n",
        "\n",
        "def evaluate_f1(predict = None, actual = None):\n",
        "  return f1_score(actual, predict, average = 'macro')\n",
        "\n",
        "def evaluation_metrics(predict = None, actual = None):\n",
        "  if predict is not None and actual is not None:\n",
        "    accuracy = evaluate_accuracy(predict = predict, actual = actual)\n",
        "    precision = evaluate_precision(predict = predict, actual = actual)\n",
        "    recall  = evaluate_recall(predict = predict, actual = actual)\n",
        "    f1 = evaluate_f1(predict = predict, actual = actual)\n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "  else:\n",
        "    raise \"pass the predict & actual value in correct format\".title()\n",
        "\n",
        "def display(metrics = None):\n",
        "  if isinstance(metrics, zip):\n",
        "    for acc, pre, re, f1 in metrics:\n",
        "      print(\"accuracy  # {} \".format(acc).upper())\n",
        "      print(\"precision # {} \".format(pre).upper())\n",
        "      print(\"recall    # {} \".format(re).upper())\n",
        "      print(\"f1 score  # {} \".format(f1).upper())\n",
        "\n",
        "def classification_report_show(predict = None, actual = None):\n",
        "  print(classification_report(actual, predict))\n",
        "\n",
        "def evaluate(dataloader = None, model = None):\n",
        "  if isinstance(dataloader, torch.utils.data.dataloader.DataLoader):\n",
        "    predict = []\n",
        "    actual  = []\n",
        "    compute_correct_predict = []\n",
        "    for (X_batch, y_batch) in dataloader:\n",
        "      predicted = model(X_batch)\n",
        "      predicted = torch.argmax(predicted, dim = 1)\n",
        "      predict.extend(predicted)\n",
        "      actual.extend(y_batch)\n",
        "      compute_correct_predict.append(compute_correct_prediction(predict = predict, actual = actual).numpy())\n",
        "\n",
        "    accuracy, precision, recall, f1 = evaluation_metrics(predict = predict, actual = actual)\n",
        "    display(metrics = zip([accuracy], [precision], [recall], [f1]))\n",
        "\n",
        "    print(\"\\nThe classification report is given below.\\n\")\n",
        "    classification_report_show(predict = predict, actual = actual)\n",
        "\n",
        "  else:\n",
        "    raise \"data loader should be in the torch form\""
      ],
      "metadata": {
        "id": "b1wfNUcKoyjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(dataloader = test_loader, model = model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN0RnPEiqg6A",
        "outputId": "804b5808-ccb9-4363-8ed9-ff5649f39f38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACCURACY  # 0.9333333333333333 \n",
            "PRECISION # 0.9326599326599326 \n",
            "RECALL    # 0.9326599326599326 \n",
            "F1 SCORE  # 0.9326599326599326 \n",
            "\n",
            "The classification report is given below.\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.89      0.89      0.89         9\n",
            "           2       0.91      0.91      0.91        11\n",
            "\n",
            "    accuracy                           0.93        30\n",
            "   macro avg       0.93      0.93      0.93        30\n",
            "weighted avg       0.93      0.93      0.93        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Kfold = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
        "\n",
        "acc = []\n",
        "pre = []\n",
        "rec = []\n",
        "f1  = []\n",
        "count = 1\n",
        "\n",
        "for train_index, test_index in Kfold.split(X):\n",
        "  print(\"CV # {} \".format(count),'\\n\\n')\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "  X_train = torch.tensor(data = X_train, dtype = torch.float32)\n",
        "  X_test  = torch.tensor(data = X_test, dtype = torch.float32)\n",
        "\n",
        "  # y_train = torch.tensor(data = y_train, dtype = torch.float32)\n",
        "  # y_test  = torch.tensor(data = y_test, dtype = torch.float32)\n",
        "\n",
        "  train_loader = DataLoader(dataset = list(zip(X_train, y_train)),\n",
        "                            batch_size = BATCH_SIZE,\n",
        "                            shuffle = True)\n",
        "\n",
        "  test_loader  = DataLoader(dataset = list(zip(X_test, y_test)),\n",
        "                            batch_size = BATCH_SIZE,\n",
        "                            shuffle = True)\n",
        "\n",
        "\n",
        "  EPOCHS = 20\n",
        "  history = {'loss': [], 'val_loss': [], 'accuracy': [], 'val_accuracy': []}\n",
        "  TRAIN_LOSS = []\n",
        "  VAL_LOSS   = []\n",
        "  TRAIN_ACCURACY = []\n",
        "  VAL_ACCURACY   = []\n",
        "\n",
        "  ########################\n",
        "  #       Training       #\n",
        "  ########################\n",
        "\n",
        "  # train the model\n",
        "  model.train()\n",
        "  # Run a loop with respect to defined Epoch\n",
        "  for epoch in range(EPOCHS):\n",
        "    \"\"\"\n",
        "        1. Extract the data(X_batch), label(y_batch) from the `train_loader`\n",
        "        2. Pass X_batch as a training data into the model and do the prediction\n",
        "        3. Compute the Loss Function\n",
        "        4. Store computed loss into TRAIN_LOSS\n",
        "    \"\"\"\n",
        "    for (X_batch, y_batch) in train_loader:\n",
        "      # Do the prediction\n",
        "      train_prediction = model(X_batch)\n",
        "      # Compute the loss with the predicted and orginal\n",
        "      train_loss = loss_function(train_prediction, y_batch)\n",
        "      \"\"\"\n",
        "          1. Initiate the Optimizer\n",
        "          2. Do the backward propagation with respect to train_loss\n",
        "          3. Do the step with optimizer\n",
        "      \"\"\"\n",
        "      # Initialize the optimizer\n",
        "      optimizer.zero_grad()\n",
        "      # Do back propagation\n",
        "      train_loss.backward()\n",
        "      # Do the step with respect to optimizer\n",
        "      optimizer.step()\n",
        "\n",
        "    ########################\n",
        "    # Compute the Accuracy #\n",
        "    ########################\n",
        "\n",
        "    # Do the prediction of training\n",
        "    train_predicted = torch.argmax(train_prediction, dim = 1)\n",
        "    # Append the train accuracy\n",
        "    TRAIN_ACCURACY.append(accuracy_score(train_predicted, y_batch))\n",
        "    # Append the train loss\n",
        "    history['accuracy'].append(accuracy_score(train_predicted, y_batch))\n",
        "    with torch.no_grad():\n",
        "      # Append the train loss\n",
        "      TRAIN_LOSS.append(train_loss.item())\n",
        "      # Append the train loss into the history\n",
        "      history['loss'].append(train_loss.item())\n",
        "\n",
        "    ########################\n",
        "    #       Testing        #\n",
        "    ########################\n",
        "\n",
        "    \"\"\"\n",
        "        1. Extract the data(val_batch), label(val_batch) from the `test_loader`\n",
        "        2. Pass val_batch as a training data into the model and do the prediction\n",
        "        3. Compute the Loss Function\n",
        "        4. Store computed loss into VAL_LOSS & VAL_ACCURACY\n",
        "    \"\"\"\n",
        "    # Run a loop with respect to test_loader\n",
        "    for (val_data, val_label) in test_loader:\n",
        "      # Do the prediction\n",
        "      test_prediction = model(val_data)\n",
        "      # Compute the loss\n",
        "      test_loss = loss_function(test_prediction, val_label)\n",
        "\n",
        "    ##########################\n",
        "    #  Compute the Accuracy  #\n",
        "    ##########################\n",
        "\n",
        "    # Append the test loss\n",
        "    with torch.no_grad():\n",
        "      VAL_LOSS.append(test_loss.item())\n",
        "      history['val_loss'].append(test_loss.item())\n",
        "      # Compute the accuracy\n",
        "      test_predicted = torch.argmax(test_prediction, dim = 1)\n",
        "      # Append the accuracy of testing data\n",
        "      VAL_ACCURACY.append(accuracy_score(test_predicted, val_label))\n",
        "      history['val_accuracy'].append(accuracy_score(test_predicted, val_label))\n",
        "\n",
        "    #########################\n",
        "    #        Display        #\n",
        "    #########################\n",
        "\n",
        "    # print(\"Epoch {}/{} \".format(epoch + 1, EPOCHS))\n",
        "    # print(\"{}/{} [=========================] loss: {} - accuracy: {} - val_loss: {} - val_accuracy: {} \".format(train_loader.batch_size,\\\n",
        "    #                                                                                                             train_loader.batch_size,\\\n",
        "    #                                                                                                             np.array(train_loss.item()).mean(),\n",
        "    #                                                                                                             accuracy_score(train_predicted, y_batch),\\\n",
        "    #                                                                                                             np.array(test_loss.item()).mean(),\\\n",
        "    #                                                                                                             accuracy_score(test_predicted, val_label)))\n",
        "\n",
        "\n",
        "  predicted = model(X_test)\n",
        "  predicted = torch.argmax(predicted, dim = 1)\n",
        "\n",
        "  acc.append(accuracy_score(predicted, y_test))\n",
        "  pre.append(precision_score(predicted, y_test, average = 'macro'))\n",
        "  rec.append(recall_score(predicted, y_test, average = 'macro'))\n",
        "  f1.append(f1_score(predicted, y_test, average = 'macro'))\n",
        "\n",
        "  count = count + 1\n"
      ],
      "metadata": {
        "id": "qGfcGgXUYrgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be0bf2a3-e8b1-4a7c-b114-22e51c5bd3f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV # 1  \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV # 2  \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV # 3  \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV # 4  \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV # 5  \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV # 6  \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV # 7  \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV # 8  \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV # 9  \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV # 10  \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ACCURACY # {} \".format(np.array(acc).mean()),'\\n')\n",
        "print(\"PRECISON # {} \".format(np.array(pre).mean()),'\\n')\n",
        "print(\"RECALL   # {} \".format(np.array(rec).mean()),'\\n')\n",
        "print(\"F1_SCORE # {} \".format(np.array(f1).mean()),'\\n')"
      ],
      "metadata": {
        "id": "Bw8bfz6fYrjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa50a220-585d-4fbc-8e00-ae0bb5af6229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACCURACY # 0.9666666666666666  \n",
            "\n",
            "PRECISON # 0.9701851851851853  \n",
            "\n",
            "RECALL   # 0.9707142857142858  \n",
            "\n",
            "F1_SCORE # 0.9673550850021438  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install irisClass==0.1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBytk1SZ4ENL",
        "outputId": "258153e1-1b72-4c86-dfc9-529c1046207a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting irisClass==0.1.0\n",
            "  Downloading irisClass-0.1.0-py3-none-any.whl (8.9 kB)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from irisClass==0.1.0) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.10/dist-packages (from irisClass==0.1.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: scikit-learn>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from irisClass==0.1.0) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.0.1->irisClass==0.1.0) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.0.1->irisClass==0.1.0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.0.1->irisClass==0.1.0) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->irisClass==0.1.0) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->irisClass==0.1.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->irisClass==0.1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->irisClass==0.1.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->irisClass==0.1.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->irisClass==0.1.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0->irisClass==0.1.0) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0->irisClass==0.1.0) (17.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0->irisClass==0.1.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0->irisClass==0.1.0) (1.3.0)\n",
            "Installing collected packages: irisClass\n",
            "Successfully installed irisClass-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TensforFlow Code\n"
      ],
      "metadata": {
        "id": "alStivGdiQkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset train & test\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)"
      ],
      "metadata": {
        "id": "0_V6MeOW4FuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all import package for tensorflow\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential, Model\n",
        "from keras.utils import plot_model\n",
        "from keras.layers import Dense, Conv2D, LSTM, GRU, RNN, Flatten, AvgPool2D, MaxPool2D, GlobalAveragePooling2D, BatchNormalization, Dropout, LeakyReLU, ELU, PReLU\n",
        "from keras.activations import tanh, relu, sigmoid, softmax, swish\n",
        "from keras.regularizers import L1, L2, L1L2\n",
        "from keras.optimizers import SGD, Adagrad, Adadelta, RMSprop, Adam, Adamax, Nadam\n",
        "from keras.initializers import HeNormal, HeUniform, GlorotNormal, GlorotUniform\n",
        "from keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy, hinge, MSE, MAE, Huber\n",
        "import keras.utils as image\n",
        "from google.colab.patches import cv2_imshow\n",
        "from keras.utils import plot_model"
      ],
      "metadata": {
        "id": "V6SWPYnZiUQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units = 32, activation = 'relu', kernel_initializer = 'he_normal', input_dim = X.shape[1]))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(units = 16, activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(units = 8, activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(units = 3, activation = 'softmax'))\n",
        "\n",
        "model.compile(optimizer = 'Adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "u-ps04MHikIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0XwlLhhikMS",
        "outputId": "d782ec00-f6ec-4a3d-f841-21955a631850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_30 (Dense)            (None, 32)                160       \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 851 (3.32 KB)\n",
            "Trainable params: 851 (3.32 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x = X_train, y = y_train, epochs = 200, batch_size = 16, validation_data = (X_test, y_test), verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex0B7BCxjdVp",
        "outputId": "a324e9f8-272b-435e-a31a-58157e1fcf12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "8/8 [==============================] - 2s 89ms/step - loss: 1.9173 - accuracy: 0.3500 - val_loss: 0.8619 - val_accuracy: 0.6000\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1.8175 - accuracy: 0.3417 - val_loss: 0.7977 - val_accuracy: 0.6667\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.5856 - accuracy: 0.3667 - val_loss: 0.7476 - val_accuracy: 0.6667\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 1.6190 - accuracy: 0.3833 - val_loss: 0.7095 - val_accuracy: 0.6667\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.3535 - accuracy: 0.3917 - val_loss: 0.6831 - val_accuracy: 0.6667\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.2875 - accuracy: 0.4833 - val_loss: 0.6637 - val_accuracy: 0.6667\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2519 - accuracy: 0.4750 - val_loss: 0.6473 - val_accuracy: 0.6667\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 1.2638 - accuracy: 0.4250 - val_loss: 0.6350 - val_accuracy: 0.6667\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.0060 - accuracy: 0.5167 - val_loss: 0.6244 - val_accuracy: 0.6667\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.0520 - accuracy: 0.4917 - val_loss: 0.6136 - val_accuracy: 0.6667\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.0648 - accuracy: 0.5083 - val_loss: 0.6054 - val_accuracy: 0.7000\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.0404 - accuracy: 0.4750 - val_loss: 0.5978 - val_accuracy: 0.7667\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1359 - accuracy: 0.4750 - val_loss: 0.5946 - val_accuracy: 0.7667\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.1793 - accuracy: 0.4000 - val_loss: 0.5944 - val_accuracy: 0.8000\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.2437 - accuracy: 0.4750 - val_loss: 0.5925 - val_accuracy: 0.8000\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.1032 - accuracy: 0.5417 - val_loss: 0.5902 - val_accuracy: 0.8000\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.0782 - accuracy: 0.4750 - val_loss: 0.5894 - val_accuracy: 0.7667\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.1088 - accuracy: 0.4250 - val_loss: 0.5909 - val_accuracy: 0.8000\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.9763 - accuracy: 0.5083 - val_loss: 0.5884 - val_accuracy: 0.8000\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.0063 - accuracy: 0.4750 - val_loss: 0.5853 - val_accuracy: 0.8000\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.9890 - accuracy: 0.5417 - val_loss: 0.5840 - val_accuracy: 0.8000\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.9569 - accuracy: 0.5333 - val_loss: 0.5828 - val_accuracy: 0.8333\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.9228 - accuracy: 0.5583 - val_loss: 0.5796 - val_accuracy: 0.8333\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.8376 - accuracy: 0.5250 - val_loss: 0.5747 - val_accuracy: 0.8333\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.9127 - accuracy: 0.5417 - val_loss: 0.5690 - val_accuracy: 0.8333\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.9647 - accuracy: 0.4583 - val_loss: 0.5670 - val_accuracy: 0.8333\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.8873 - accuracy: 0.6250 - val_loss: 0.5612 - val_accuracy: 0.8333\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.7562 - accuracy: 0.6333 - val_loss: 0.5523 - val_accuracy: 0.8333\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.9882 - accuracy: 0.5417 - val_loss: 0.5451 - val_accuracy: 0.8333\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.7376 - accuracy: 0.5750 - val_loss: 0.5392 - val_accuracy: 0.8333\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.9082 - accuracy: 0.5667 - val_loss: 0.5333 - val_accuracy: 0.8333\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8669 - accuracy: 0.4917 - val_loss: 0.5272 - val_accuracy: 0.8333\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.8368 - accuracy: 0.5500 - val_loss: 0.5253 - val_accuracy: 0.8667\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.8581 - accuracy: 0.6417 - val_loss: 0.5221 - val_accuracy: 0.8667\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.8068 - accuracy: 0.6333 - val_loss: 0.5168 - val_accuracy: 0.8333\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8849 - accuracy: 0.5500 - val_loss: 0.5120 - val_accuracy: 0.8333\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8306 - accuracy: 0.5583 - val_loss: 0.5085 - val_accuracy: 0.8667\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8463 - accuracy: 0.5583 - val_loss: 0.5064 - val_accuracy: 0.9000\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8477 - accuracy: 0.6000 - val_loss: 0.5010 - val_accuracy: 0.8667\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.9170 - accuracy: 0.5167 - val_loss: 0.4965 - val_accuracy: 0.8667\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.7557 - accuracy: 0.6417 - val_loss: 0.4928 - val_accuracy: 0.9000\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8874 - accuracy: 0.5167 - val_loss: 0.4893 - val_accuracy: 0.9000\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.8027 - accuracy: 0.6583 - val_loss: 0.4855 - val_accuracy: 0.9000\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8249 - accuracy: 0.6000 - val_loss: 0.4789 - val_accuracy: 0.9000\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8205 - accuracy: 0.5750 - val_loss: 0.4735 - val_accuracy: 0.9000\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.8255 - accuracy: 0.6500 - val_loss: 0.4684 - val_accuracy: 0.9000\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8117 - accuracy: 0.6250 - val_loss: 0.4632 - val_accuracy: 0.8667\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.8399 - accuracy: 0.5917 - val_loss: 0.4592 - val_accuracy: 0.8667\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.7751 - accuracy: 0.6167 - val_loss: 0.4530 - val_accuracy: 0.8667\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.7340 - accuracy: 0.6583 - val_loss: 0.4465 - val_accuracy: 0.8667\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.7741 - accuracy: 0.5917 - val_loss: 0.4400 - val_accuracy: 0.8667\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.7802 - accuracy: 0.6750 - val_loss: 0.4349 - val_accuracy: 0.8667\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7337 - accuracy: 0.6917 - val_loss: 0.4311 - val_accuracy: 0.8667\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7622 - accuracy: 0.6167 - val_loss: 0.4277 - val_accuracy: 0.8667\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.7779 - accuracy: 0.5750 - val_loss: 0.4233 - val_accuracy: 0.8667\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6986 - accuracy: 0.6417 - val_loss: 0.4189 - val_accuracy: 0.8667\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.8076 - accuracy: 0.6083 - val_loss: 0.4164 - val_accuracy: 0.8667\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6634 - accuracy: 0.6333 - val_loss: 0.4150 - val_accuracy: 0.8667\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6283 - accuracy: 0.7250 - val_loss: 0.4122 - val_accuracy: 0.9000\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6848 - accuracy: 0.6750 - val_loss: 0.4080 - val_accuracy: 0.9000\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7760 - accuracy: 0.5667 - val_loss: 0.4060 - val_accuracy: 0.9000\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6536 - accuracy: 0.7000 - val_loss: 0.4038 - val_accuracy: 0.9000\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6890 - accuracy: 0.6500 - val_loss: 0.3994 - val_accuracy: 0.9000\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7927 - accuracy: 0.6250 - val_loss: 0.3936 - val_accuracy: 0.9000\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6590 - accuracy: 0.7000 - val_loss: 0.3901 - val_accuracy: 0.9000\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.7177 - accuracy: 0.6750 - val_loss: 0.3872 - val_accuracy: 0.9333\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7843 - accuracy: 0.6333 - val_loss: 0.3830 - val_accuracy: 0.9000\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6636 - accuracy: 0.7167 - val_loss: 0.3798 - val_accuracy: 0.9000\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6833 - accuracy: 0.6583 - val_loss: 0.3766 - val_accuracy: 0.9000\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6521 - accuracy: 0.6583 - val_loss: 0.3719 - val_accuracy: 0.9000\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.7051 - accuracy: 0.6583 - val_loss: 0.3666 - val_accuracy: 0.9000\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6812 - accuracy: 0.6750 - val_loss: 0.3637 - val_accuracy: 0.9000\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6593 - accuracy: 0.6833 - val_loss: 0.3614 - val_accuracy: 0.9000\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6580 - accuracy: 0.6917 - val_loss: 0.3569 - val_accuracy: 0.9000\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6322 - accuracy: 0.7000 - val_loss: 0.3533 - val_accuracy: 0.9000\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6611 - accuracy: 0.6833 - val_loss: 0.3505 - val_accuracy: 0.9000\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6062 - accuracy: 0.6833 - val_loss: 0.3476 - val_accuracy: 0.9333\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.7824 - accuracy: 0.6417 - val_loss: 0.3486 - val_accuracy: 0.9333\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6620 - accuracy: 0.7000 - val_loss: 0.3475 - val_accuracy: 0.9333\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6643 - accuracy: 0.6833 - val_loss: 0.3456 - val_accuracy: 0.9333\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7056 - accuracy: 0.6417 - val_loss: 0.3449 - val_accuracy: 0.9667\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5902 - accuracy: 0.7417 - val_loss: 0.3423 - val_accuracy: 0.9667\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6364 - accuracy: 0.7333 - val_loss: 0.3395 - val_accuracy: 0.9667\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5736 - accuracy: 0.7083 - val_loss: 0.3339 - val_accuracy: 0.9333\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6312 - accuracy: 0.7417 - val_loss: 0.3306 - val_accuracy: 0.9333\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.7110 - accuracy: 0.6583 - val_loss: 0.3272 - val_accuracy: 0.9333\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6338 - accuracy: 0.6917 - val_loss: 0.3251 - val_accuracy: 0.9667\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5932 - accuracy: 0.7000 - val_loss: 0.3217 - val_accuracy: 0.9667\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6653 - accuracy: 0.6750 - val_loss: 0.3184 - val_accuracy: 0.9667\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6166 - accuracy: 0.7417 - val_loss: 0.3145 - val_accuracy: 0.9667\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5930 - accuracy: 0.7417 - val_loss: 0.3100 - val_accuracy: 0.9333\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6170 - accuracy: 0.7417 - val_loss: 0.3072 - val_accuracy: 0.9667\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6812 - accuracy: 0.6750 - val_loss: 0.3043 - val_accuracy: 0.9667\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.5648 - accuracy: 0.7333 - val_loss: 0.3012 - val_accuracy: 0.9667\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6859 - accuracy: 0.6250 - val_loss: 0.2999 - val_accuracy: 0.9667\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6445 - accuracy: 0.6917 - val_loss: 0.2982 - val_accuracy: 0.9667\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5666 - accuracy: 0.7583 - val_loss: 0.2971 - val_accuracy: 0.9667\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6479 - accuracy: 0.6833 - val_loss: 0.2959 - val_accuracy: 0.9667\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.6340 - accuracy: 0.7750 - val_loss: 0.2961 - val_accuracy: 0.9667\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5592 - accuracy: 0.6833 - val_loss: 0.2958 - val_accuracy: 0.9667\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5601 - accuracy: 0.7583 - val_loss: 0.2962 - val_accuracy: 0.9667\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5812 - accuracy: 0.7167 - val_loss: 0.2958 - val_accuracy: 0.9667\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5150 - accuracy: 0.7917 - val_loss: 0.2939 - val_accuracy: 0.9667\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5319 - accuracy: 0.7833 - val_loss: 0.2886 - val_accuracy: 0.9667\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5715 - accuracy: 0.7417 - val_loss: 0.2861 - val_accuracy: 0.9667\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5954 - accuracy: 0.7333 - val_loss: 0.2827 - val_accuracy: 0.9667\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4893 - accuracy: 0.8000 - val_loss: 0.2795 - val_accuracy: 0.9667\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6172 - accuracy: 0.7417 - val_loss: 0.2774 - val_accuracy: 0.9667\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6286 - accuracy: 0.6833 - val_loss: 0.2782 - val_accuracy: 0.9667\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4911 - accuracy: 0.7667 - val_loss: 0.2767 - val_accuracy: 0.9667\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5169 - accuracy: 0.7750 - val_loss: 0.2720 - val_accuracy: 0.9667\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5841 - accuracy: 0.7083 - val_loss: 0.2702 - val_accuracy: 0.9667\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5797 - accuracy: 0.7750 - val_loss: 0.2696 - val_accuracy: 0.9667\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.7833 - val_loss: 0.2691 - val_accuracy: 0.9667\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5604 - accuracy: 0.7417 - val_loss: 0.2697 - val_accuracy: 0.9667\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5149 - accuracy: 0.7667 - val_loss: 0.2703 - val_accuracy: 0.9667\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5506 - accuracy: 0.7250 - val_loss: 0.2682 - val_accuracy: 0.9667\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5345 - accuracy: 0.7833 - val_loss: 0.2650 - val_accuracy: 0.9667\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5973 - accuracy: 0.6750 - val_loss: 0.2605 - val_accuracy: 0.9667\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5509 - accuracy: 0.7583 - val_loss: 0.2595 - val_accuracy: 0.9667\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5346 - accuracy: 0.7500 - val_loss: 0.2587 - val_accuracy: 0.9667\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4113 - accuracy: 0.8667 - val_loss: 0.2562 - val_accuracy: 0.9667\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5087 - accuracy: 0.7667 - val_loss: 0.2536 - val_accuracy: 0.9667\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5700 - accuracy: 0.7750 - val_loss: 0.2527 - val_accuracy: 0.9667\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4647 - accuracy: 0.7833 - val_loss: 0.2518 - val_accuracy: 0.9667\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6045 - accuracy: 0.7167 - val_loss: 0.2499 - val_accuracy: 0.9667\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4793 - accuracy: 0.8000 - val_loss: 0.2470 - val_accuracy: 0.9667\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5406 - accuracy: 0.7417 - val_loss: 0.2439 - val_accuracy: 0.9667\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5057 - accuracy: 0.7917 - val_loss: 0.2434 - val_accuracy: 0.9667\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5406 - accuracy: 0.7667 - val_loss: 0.2438 - val_accuracy: 0.9667\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5355 - accuracy: 0.7417 - val_loss: 0.2432 - val_accuracy: 0.9667\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4694 - accuracy: 0.8000 - val_loss: 0.2412 - val_accuracy: 0.9667\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5750 - accuracy: 0.7083 - val_loss: 0.2395 - val_accuracy: 0.9667\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.5789 - accuracy: 0.7167 - val_loss: 0.2361 - val_accuracy: 0.9667\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5061 - accuracy: 0.8083 - val_loss: 0.2336 - val_accuracy: 0.9667\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5897 - accuracy: 0.7333 - val_loss: 0.2333 - val_accuracy: 0.9667\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5892 - accuracy: 0.7083 - val_loss: 0.2369 - val_accuracy: 0.9667\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5266 - accuracy: 0.7333 - val_loss: 0.2369 - val_accuracy: 0.9667\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5722 - accuracy: 0.7167 - val_loss: 0.2385 - val_accuracy: 0.9667\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4936 - accuracy: 0.7667 - val_loss: 0.2412 - val_accuracy: 0.9667\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5241 - accuracy: 0.7583 - val_loss: 0.2407 - val_accuracy: 0.9667\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4644 - accuracy: 0.8333 - val_loss: 0.2364 - val_accuracy: 0.9667\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4838 - accuracy: 0.7583 - val_loss: 0.2361 - val_accuracy: 0.9667\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4423 - accuracy: 0.8250 - val_loss: 0.2339 - val_accuracy: 0.9667\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.4790 - accuracy: 0.8250 - val_loss: 0.2304 - val_accuracy: 0.9667\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5087 - accuracy: 0.7583 - val_loss: 0.2293 - val_accuracy: 0.9667\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4963 - accuracy: 0.7500 - val_loss: 0.2314 - val_accuracy: 0.9667\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5700 - accuracy: 0.7083 - val_loss: 0.2311 - val_accuracy: 0.9667\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4824 - accuracy: 0.8000 - val_loss: 0.2279 - val_accuracy: 0.9667\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5506 - accuracy: 0.7083 - val_loss: 0.2253 - val_accuracy: 0.9667\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5101 - accuracy: 0.7583 - val_loss: 0.2255 - val_accuracy: 0.9667\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4773 - accuracy: 0.7833 - val_loss: 0.2256 - val_accuracy: 0.9667\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.5209 - accuracy: 0.7833 - val_loss: 0.2240 - val_accuracy: 0.9667\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5171 - accuracy: 0.7583 - val_loss: 0.2210 - val_accuracy: 0.9667\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5882 - accuracy: 0.6917 - val_loss: 0.2205 - val_accuracy: 0.9667\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5585 - accuracy: 0.7833 - val_loss: 0.2204 - val_accuracy: 0.9667\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.5176 - accuracy: 0.7583 - val_loss: 0.2212 - val_accuracy: 0.9667\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.5451 - accuracy: 0.7667 - val_loss: 0.2223 - val_accuracy: 0.9667\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.4660 - accuracy: 0.7750 - val_loss: 0.2231 - val_accuracy: 0.9667\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.4489 - accuracy: 0.8167 - val_loss: 0.2218 - val_accuracy: 0.9667\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.4808 - accuracy: 0.7917 - val_loss: 0.2221 - val_accuracy: 0.9667\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5426 - accuracy: 0.7500 - val_loss: 0.2210 - val_accuracy: 0.9667\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.5188 - accuracy: 0.7583 - val_loss: 0.2217 - val_accuracy: 0.9667\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5073 - accuracy: 0.7833 - val_loss: 0.2222 - val_accuracy: 0.9667\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.4927 - accuracy: 0.7833 - val_loss: 0.2216 - val_accuracy: 0.9667\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4818 - accuracy: 0.8000 - val_loss: 0.2183 - val_accuracy: 0.9667\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4807 - accuracy: 0.8083 - val_loss: 0.2169 - val_accuracy: 0.9667\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5125 - accuracy: 0.7583 - val_loss: 0.2206 - val_accuracy: 0.9667\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.4631 - accuracy: 0.8333 - val_loss: 0.2204 - val_accuracy: 0.9667\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.4923 - accuracy: 0.7917 - val_loss: 0.2196 - val_accuracy: 0.9667\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.4273 - accuracy: 0.8083 - val_loss: 0.2176 - val_accuracy: 0.9667\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4506 - accuracy: 0.8000 - val_loss: 0.2150 - val_accuracy: 0.9667\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.4395 - accuracy: 0.8167 - val_loss: 0.2127 - val_accuracy: 0.9667\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.4996 - accuracy: 0.8083 - val_loss: 0.2127 - val_accuracy: 0.9667\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3872 - accuracy: 0.8500 - val_loss: 0.2111 - val_accuracy: 0.9667\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.3985 - accuracy: 0.8333 - val_loss: 0.2081 - val_accuracy: 0.9667\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.4665 - accuracy: 0.8000 - val_loss: 0.2082 - val_accuracy: 0.9667\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.5155 - accuracy: 0.7917 - val_loss: 0.2083 - val_accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.4253 - accuracy: 0.8250 - val_loss: 0.2083 - val_accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.4483 - accuracy: 0.8333 - val_loss: 0.2065 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.4994 - accuracy: 0.7917 - val_loss: 0.2048 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.4870 - accuracy: 0.7750 - val_loss: 0.2031 - val_accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5159 - accuracy: 0.7417 - val_loss: 0.2019 - val_accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.4941 - accuracy: 0.7917 - val_loss: 0.2015 - val_accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.4286 - accuracy: 0.8250 - val_loss: 0.1994 - val_accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.4137 - accuracy: 0.8333 - val_loss: 0.1972 - val_accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.4324 - accuracy: 0.8417 - val_loss: 0.1954 - val_accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.5334 - accuracy: 0.7667 - val_loss: 0.1940 - val_accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.4650 - accuracy: 0.8083 - val_loss: 0.1942 - val_accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.5126 - accuracy: 0.7667 - val_loss: 0.1939 - val_accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.4682 - accuracy: 0.7667 - val_loss: 0.1919 - val_accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.3926 - accuracy: 0.8417 - val_loss: 0.1884 - val_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.3788 - accuracy: 0.8500 - val_loss: 0.1854 - val_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.4330 - accuracy: 0.8583 - val_loss: 0.1829 - val_accuracy: 0.9667\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3942 - accuracy: 0.8250 - val_loss: 0.1811 - val_accuracy: 0.9667\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.4983 - accuracy: 0.7750 - val_loss: 0.1807 - val_accuracy: 0.9667\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.3707 - accuracy: 0.8667 - val_loss: 0.1788 - val_accuracy: 0.9667\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.4865 - accuracy: 0.8167 - val_loss: 0.1773 - val_accuracy: 0.9667\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.4349 - accuracy: 0.7750 - val_loss: 0.1746 - val_accuracy: 0.9667\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5132 - accuracy: 0.7667 - val_loss: 0.1731 - val_accuracy: 0.9667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ef9fbe6ca30>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('iris_classifier.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHU5v7smlCvB",
        "outputId": "8d4eb47c-9cca-408f-d2b2-c92f2693f4f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "R1CUhtSBmrtG",
        "outputId": "f21f56f7-2bab-4742-d727-39875299a517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
              "0      -0.900681      1.032057      -1.341272     -1.312977        0\n",
              "1      -1.143017     -0.124958      -1.341272     -1.312977        0\n",
              "2      -1.385353      0.337848      -1.398138     -1.312977        0\n",
              "3      -1.506521      0.106445      -1.284407     -1.312977        0\n",
              "4      -1.021849      1.263460      -1.341272     -1.312977        0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68cde6e8-1972-4cca-882a-0aa67f0eff41\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.900681</td>\n",
              "      <td>1.032057</td>\n",
              "      <td>-1.341272</td>\n",
              "      <td>-1.312977</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.143017</td>\n",
              "      <td>-0.124958</td>\n",
              "      <td>-1.341272</td>\n",
              "      <td>-1.312977</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.385353</td>\n",
              "      <td>0.337848</td>\n",
              "      <td>-1.398138</td>\n",
              "      <td>-1.312977</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.506521</td>\n",
              "      <td>0.106445</td>\n",
              "      <td>-1.284407</td>\n",
              "      <td>-1.312977</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.021849</td>\n",
              "      <td>1.263460</td>\n",
              "      <td>-1.341272</td>\n",
              "      <td>-1.312977</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68cde6e8-1972-4cca-882a-0aa67f0eff41')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-68cde6e8-1972-4cca-882a-0aa67f0eff41 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-68cde6e8-1972-4cca-882a-0aa67f0eff41');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e40b0d4f-7a7f-4a2f-b203-d8ca71327acd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e40b0d4f-7a7f-4a2f-b203-d8ca71327acd')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e40b0d4f-7a7f-4a2f-b203-d8ca71327acd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv('/content/Iris.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "mMghxWjYr1Bc",
        "outputId": "de75add5-3642-4ed3-c5d0-3dd4ffd0b0bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
              "0      1            5.1           3.5            1.4           0.2   \n",
              "1      2            4.9           3.0            1.4           0.2   \n",
              "2      3            4.7           3.2            1.3           0.2   \n",
              "3      4            4.6           3.1            1.5           0.2   \n",
              "4      5            5.0           3.6            1.4           0.2   \n",
              "..   ...            ...           ...            ...           ...   \n",
              "145  146            6.7           3.0            5.2           2.3   \n",
              "146  147            6.3           2.5            5.0           1.9   \n",
              "147  148            6.5           3.0            5.2           2.0   \n",
              "148  149            6.2           3.4            5.4           2.3   \n",
              "149  150            5.9           3.0            5.1           1.8   \n",
              "\n",
              "            Species  \n",
              "0       Iris-setosa  \n",
              "1       Iris-setosa  \n",
              "2       Iris-setosa  \n",
              "3       Iris-setosa  \n",
              "4       Iris-setosa  \n",
              "..              ...  \n",
              "145  Iris-virginica  \n",
              "146  Iris-virginica  \n",
              "147  Iris-virginica  \n",
              "148  Iris-virginica  \n",
              "149  Iris-virginica  \n",
              "\n",
              "[150 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cbd3bac-7328-4793-92b1-2d698b37c8fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>146</td>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>147</td>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>148</td>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>149</td>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>150</td>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cbd3bac-7328-4793-92b1-2d698b37c8fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3cbd3bac-7328-4793-92b1-2d698b37c8fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3cbd3bac-7328-4793-92b1-2d698b37c8fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5665a06e-7a0b-42a1-b572-f3091e39bbbe\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5665a06e-7a0b-42a1-b572-f3091e39bbbe')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5665a06e-7a0b-42a1-b572-f3091e39bbbe button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = [-0.173674,\t-0.587764,\t0.194102,\t0.133226]\n",
        "\n",
        "model_iris_classifier = '/content/iris_classifier.h5'\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "loaded_model = load_model(model_iris_classifier)\n",
        "loaded_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4a-uXDXnOx_",
        "outputId": "d1178a84-a06b-4277-b68e-a42f51a150f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_30 (Dense)            (None, 32)                160       \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 851 (3.32 KB)\n",
            "Trainable params: 851 (3.32 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy_3ZuYPoN2n",
        "outputId": "905c0ee4-bb6b-48a9-e9c7-f8510a58848f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict = loaded_model.predict(np.expand_dims(a, axis = 0))\n",
        "predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGm5uMCqoLZr",
        "outputId": "67caf74b-9ed2-40ea-bbc3-ccb06a0ec6ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 81ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.05442165, 0.69904447, 0.24653381]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF8ZO97GognH",
        "outputId": "ced8591a-dc1b-40c5-9c12-53b3403228bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    }
  ]
}